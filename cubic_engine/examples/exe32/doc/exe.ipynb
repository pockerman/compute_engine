{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 32: Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "* [Acknowledgements](#ackw)\n",
    "* [Overview](#overview) \n",
    "    * [Naive Bayes classification](#ekf)\n",
    "    * [Multinomial naive Bayes classification](#sumekf)\n",
    "    * [Test Case](#motion_model)\n",
    "* [Include files](#include_files)\n",
    "* [The main function](#m_func)\n",
    "* [Results](#results)\n",
    "* [Source Code](#source_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"overview\"></a> Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will discuss <a href=\"https://en.wikipedia.org/wiki/Principal_component_analysis\">Principal Component Analysis</a> for dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction refres to a number of techniques for reducing the dimensions associated with a data set. Consider, for example, a data set where each input point has five features. A dimensionality reduction technique can help us reduce the number of features to three or two. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One perhaps aparent reason why one would like to reduce the number of features in a data set is visualization. It is easy to visualize two or even three dimensional data sets. However, as the dimensions increase, the difficulty of doing so also increases both in terms of computing power required as well as the conceptual understanding.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from visualization, one other reason why someone would like to reduce the number of dimensions of a data set is that a large number  of input features can cause poor performance of ML algorithms. This is frequently abbreviated as the curse of dimensionality. Furthermore, often fewer input dimensions translate to fewer model parameters or simpler model structure in general. A model with too many parameters is likely to overfit the training set and therefore it may not perform well on new data. Finally, dimensionality reduction may also be appropriate when the variables in a dataset are noisy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"ekf\"></a> Naive Bayes classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial naive Bayes classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first consider the following toy example. The data set $\\mathbf{X}$ is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "DynMat<real_t> X(6, 2);\n",
    "X(0,0) = -1.;\n",
    "X(0,1) = -1.;\n",
    "    \n",
    "X(1,0) = -2.;\n",
    "X(1,1) = -1.;\n",
    "    \n",
    "X(2,0) = -3.;\n",
    "X(2,1) = -2.;\n",
    "    \n",
    "X(3,0) = 1.;\n",
    "X(3,1) = 1.;\n",
    "    \n",
    "X(4,0) = 2.;\n",
    "X(4,1) = 1.;\n",
    "    \n",
    "X(5,0) = 3.;\n",
    "X(5,1) = 2.;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the empirical mean for each of the two columns is zero. The <a href=\"https://bitbucket.org/blaze-lib/blaze/src/master/\">Blaze</a> library that we use to represent matrices and vectors has support for SVD. We will use the following function in the code below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "template< typename MT1, bool SO, typename VT, bool TF, typename MT2, typename MT3 >\n",
    "void svd( const DenseMatrix<MT1,SO>& A, DenseMatrix<MT2,SO>& U,\n",
    "          DenseVector<VT,TF>& s, DenseMatrix<MT3,SO>& V );\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above is rather simple. We will use the <a href=\"https://archive.ics.uci.edu/ml/datasets/wine\">wine</a> data set as a more complicated example. This data set has 178 examples and 12 features. We can load the data set by issuing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "auto data = kernel::load_wine_data_set(false);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we will use the ```PCA``` class that helps us with maintaining the relevant information. Note that the class only transforms the supplied data set according to the transformation given above. However, it is the application's responsibility to scale the data appropriately if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"include_files\"></a> Include files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#include \"cubic_engine/base/cubic_engine_types.h\"\n",
    "#include \"kernel/maths/matrix_utilities.h\"\n",
    "#include \"kernel/utilities/data_set_loaders.h\"\n",
    "#include \"kernel/maths/pca.h\"\n",
    "\n",
    "#include <iostream>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"m_func\"></a> The main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "namespace example\n",
    "{\n",
    "\n",
    "using cengine::uint_t;\n",
    "using cengine::real_t;\n",
    "using cengine::DynMat;\n",
    "using cengine::DynVec;\n",
    "\n",
    "void test_case_1(){\n",
    "\n",
    "    DynMat<real_t> X(6, 2);\n",
    "    X(0,0) = -1.;\n",
    "    X(0,1) = -1.;\n",
    "\n",
    "    X(1,0) = -2.;\n",
    "    X(1,1) = -1.;\n",
    "\n",
    "    X(2,0) = -3.;\n",
    "    X(2,1) = -2.;\n",
    "\n",
    "    X(3,0) = 1.;\n",
    "    X(3,1) = 1.;\n",
    "\n",
    "    X(4,0) = 2.;\n",
    "    X(4,1) = 1.;\n",
    "\n",
    "    X(5,0) = 3.;\n",
    "    X(5,1) = 2.;\n",
    "\n",
    "    // caluclate the sample variance\n",
    "    // of each of the 3 variables (columns)\n",
    "    auto col1 = kernel::get_column(X, 0);\n",
    "    auto col2 = kernel::get_column(X, 1);\n",
    "\n",
    "    auto col1_var = var(col1);\n",
    "    auto col2_var = var(col2);\n",
    "\n",
    "    std::cout<<\"Variable 1 variance: \"<<col1_var<<std::endl;\n",
    "    std::cout<<\"Variable 2 variance: \"<<col2_var<<std::endl;\n",
    "\n",
    "    // compute the total variance\n",
    "    auto total_var = col1_var + col2_var;\n",
    "\n",
    "    std::cout<<\"Total variance: \"<<total_var<<std::endl;\n",
    "\n",
    "    DynMat<real_t> U;\n",
    "    DynVec<real_t> s;\n",
    "    DynMat<real_t> V;\n",
    "\n",
    "    std::cout<<\"Variable 1 explains: \"<<col1_var/total_var<<std::endl;\n",
    "    std::cout<<\"Variable 2 explains: \"<<col2_var/total_var<<std::endl;\n",
    "\n",
    "    svd(X, U, s, V );\n",
    "\n",
    "    std::cout<<\"Singular values: \"<<s<<std::endl;\n",
    "\n",
    "    auto sum_eigen_values = 0.0;\n",
    "    for(uint_t v=0; v<s.size(); ++v){\n",
    "       sum_eigen_values += s[v]*s[v];\n",
    "    }\n",
    "\n",
    "    std::cout<<\"Sum eignenvalies: \"<<sum_eigen_values<<std::endl;\n",
    "    //std::cout<<\"Variable 1 variance: \"<<s[0]*s[0]<<std::endl;\n",
    "    //std::cout<<\"Variable 2 variance: \"<<s[1]*s[1]<<std::endl;\n",
    "    std::cout<<\"Variable 1 explains: \"<<(s[0]*s[0])/sum_eigen_values<<std::endl;\n",
    "    std::cout<<\"Variable 2 explains: \"<<(s[1]*s[1])/sum_eigen_values<<std::endl;\n",
    "\n",
    "    // Principal axes in feature space,\n",
    "    // representing the directions of maximum variance in the data.\n",
    "    // these are the columns of the V matrix\n",
    "    std::cout<<\"V matrix: \"<<V<<std::endl;\n",
    "\n",
    "    // reconstruct the data set with PCA\n",
    "    // The full principal components decomposition of\n",
    "    // X can be given as T= XW\n",
    "    DynMat<real_t> T = X*V;\n",
    "\n",
    "    // caluclate the sample variance\n",
    "    // of each of the 3 variables (columns)\n",
    "    auto pca_col1 = kernel::get_column(T, 0);\n",
    "    auto pca_col2 = kernel::get_column(T, 1);\n",
    "\n",
    "    auto pca_col1_var = var(pca_col1);\n",
    "    auto pca_col2_var = var(pca_col2);\n",
    "\n",
    "    std::cout<<\"PCA variable 1 variance: \"<<pca_col1_var<<std::endl;\n",
    "    std::cout<<\"PCA variable 2 variance: \"<<pca_col2_var<<std::endl;\n",
    "\n",
    "    // this should be the same at the total variance\n",
    "    // compute the total variance\n",
    "    auto pca_total_var = pca_col1_var + pca_col2_var;\n",
    "\n",
    "    std::cout<<\"PCA Total variance: \"<<pca_total_var<<std::endl;\n",
    "\n",
    "    std::cout<<\"PCA Variable 1 explains: \"<<pca_col1_var/pca_total_var<<std::endl;\n",
    "    std::cout<<\"PCA Variable 2 explains: \"<<pca_col2_var/pca_total_var<<std::endl;\n",
    "\n",
    "}\n",
    "\n",
    "void test_case_2(){\n",
    "\n",
    "    using  kernel::PCA;\n",
    "\n",
    "    // load the wine data set\n",
    "    auto data = kernel::load_wine_data_set(false);\n",
    "\n",
    "    // extract the column means\n",
    "    auto means = kernel::get_column_means(data.first);\n",
    "\n",
    "    // crenter the columns\n",
    "    kernel::center_columns(data.first, means);\n",
    "\n",
    "    auto variances = kernel::get_column_variances(data.first);\n",
    "    auto total_var = sum(variances);\n",
    "    std::cout<<\"Total variance: \"<<total_var<<std::endl;\n",
    "\n",
    "    for(uint_t c=0; c<variances.size(); ++c){\n",
    "        std::cout<<\"Variable: \"<<c<<\" explains: \"<<variances[c]/total_var<<std::endl;\n",
    "    }\n",
    "\n",
    "    // keep the first three components\n",
    "    // with the largest variance\n",
    "    PCA pca(3);\n",
    "\n",
    "    // transform the data\n",
    "    pca.fit(data.first);\n",
    "\n",
    "    auto singular_vals = pca.get_singular_values();\n",
    "    std::cout<<\"Singular values: \"<<singular_vals<<std::endl;\n",
    "\n",
    "    auto explained_var = pca.get_explained_variance();\n",
    "\n",
    "    for(uint_t c=0; c<explained_var.size(); ++c){\n",
    "        std::cout<<\"Component: \"<<c<<\" explains: \"<<explained_var[c]<<std::endl;\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "}\n",
    "\n",
    "int main() {\n",
    "   \n",
    "    using namespace example;\n",
    "    \n",
    "    try{\n",
    "\n",
    "        std::cout<<\"=========================\"<<std::endl;\n",
    "        std::cout<<\"Doing test 1\"<<std::endl;\n",
    "        std::cout<<\"=========================\"<<std::endl;\n",
    "        test_case_1();\n",
    "\n",
    "        std::cout<<\"=========================\"<<std::endl;\n",
    "        std::cout<<\"Doing test 2\"<<std::endl;\n",
    "        std::cout<<\"=========================\"<<std::endl;\n",
    "        test_case_2();\n",
    "    }\n",
    "    catch(std::runtime_error& e){\n",
    "        std::cerr<<\"Runtime error: \"\n",
    "                 <<e.what()<<std::endl;\n",
    "    }\n",
    "    catch(std::logic_error& e){\n",
    "        std::cerr<<\"Logic error: \"\n",
    "                 <<e.what()<<std::endl;\n",
    "    }\n",
    "    catch(...){\n",
    "        std::cerr<<\"Unknown exception was raised whilst running simulation.\"<<std::endl;\n",
    "    }\n",
    "   \n",
    "    return 0;\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"results\"></a> Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon running the driver code above we get:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "=========================\n",
    "Doing test 1\n",
    "=========================\n",
    "Variable 1 variance: 5.6\n",
    "Variable 2 variance: 2.4\n",
    "Total variance: 8\n",
    "Variable 1 explains: 0.7\n",
    "Variable 2 explains: 0.3\n",
    "Singular values: (     6.30061 )\n",
    "(    0.549804 )\n",
    "\n",
    "Sum eignenvalies: 40\n",
    "Variable 1 explains: 0.992443\n",
    "Variable 2 explains: 0.00755711\n",
    "V matrix: (    -0.838492    -0.544914 )\n",
    "(    -0.544914     0.838492 )\n",
    "\n",
    "PCA variable 1 variance: 7.93954\n",
    "PCA variable 2 variance: 0.0604569\n",
    "PCA Total variance: 8\n",
    "PCA Variable 1 explains: 0.992443\n",
    "PCA Variable 2 explains: 0.00755711\n",
    "=========================\n",
    "Doing test 2\n",
    "=========================\n",
    "Total variance: 224.788\n",
    "Variable: 0 explains: 0.00293193\n",
    "Variable: 1 explains: 0.00555198\n",
    "Variable: 2 explains: 0.000334826\n",
    "Variable: 3 explains: 0.0496143\n",
    "Variable: 4 explains: 0.907476\n",
    "Variable: 5 explains: 0.00174249\n",
    "Variable: 6 explains: 0.00443849\n",
    "Variable: 7 explains: 6.89034e-05\n",
    "Variable: 8 explains: 0.00145735\n",
    "Variable: 9 explains: 0.023909\n",
    "Variable: 10 explains: 0.000232419\n",
    "Variable: 11 explains: 0.0022425\n",
    "Singular values: (     190.221 )\n",
    "(     45.1776 )\n",
    "(     31.5194 )\n",
    "(     16.7921 )\n",
    "(     12.5484 )\n",
    "(     7.59523 )\n",
    "(      5.1764 )\n",
    "(     4.45796 )\n",
    "(     3.56478 )\n",
    "(     2.65211 )\n",
    "(     1.94634 )\n",
    "(     1.20831 )\n",
    "\n",
    "Component: 0 explains: 0.909437\n",
    "Component: 1 explains: 0.0512981\n",
    "Component: 2 explains: 0.0249696\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"source_code\"></a> Source Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"../exe.cpp\">exe.cpp</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
