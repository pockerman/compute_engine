{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "* [Overview](#overview) \n",
    "    * [Linear Regression](#linear_regression)\n",
    "    * [MLE](#mle)\n",
    "    * [Normal equations](#normal_equations)\n",
    "    * [How Good Is The Fit?](#how_good_is_the_fit)\n",
    "      * [```R^2``` Coefficient](#r2_coefficient)\n",
    "* [Include files](#include_files)\n",
    "* [Program structure](#prg_struct)\n",
    "* [The main function](#m_func)\n",
    "* [Results](#results)\n",
    "* [Source Code](#source_code)\n",
    "* [References](#refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"overview\"></a> Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://en.wikipedia.org/wiki/Linear_regression\">Linear regression</a> is the work horse of statistics and supervised machine learning [1]. Although the typical model is linear (and hence the name), when augmented with kernels or other forms of basis function expansion, it can model also non-linear relationships. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"linear_regression\"></a> Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Statistics, <a href=\"https://en.wikipedia.org/wiki/Linear_regression\">linear regression</a> is a mathematical approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). The case of one explanatory variable is called simple linear regression.  For more than one explanatory variable, the process is called multiple linear regression. The figure below shows a linear regression model fitted in a data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"linear_regression.png\" alt=\"linear regression model\"\n",
    "\ttitle=\"linear regression model\" width=\"400\" height=\"350\" />\n",
    "<figcaption>Figure: Linear regression model. Image from [2].</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrary to classification that is concerned with\n",
    "class indexes, the outcome of a linear regression model or more general of a regression model is a real number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic model has the following form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y} = w_0 + w_1x_1+...w_mx_m = \\sum_{i=0}^{m}w_ix_i, ~~x_0 = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $x_i$ are the explanatory or independent variables and $w_i$ are the parameters of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"mle\"></a> MLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is a rather simple mathematical model and to this it owes its widespread use. We still need a way to estimate the parameters vector $\\mathbf{w}$. The most common way is to compute the <a href=\"https://en.wikipedia.org/wiki/Maximum_likelihood_estimation\">MLE</a> (maximum likelihood estimate). This is defined as [1]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathbf{\\hat{w}}=\\text{argmax}_{\\mathbf{w}}log p(D|\\mathbf{w})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $D$ is the set of the observations we have at hand. Let's assume that these observations are **iid**. Hence we can write [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$l(\\mathbf{w}) = log p(D|\\mathbf{w}) = \\sum_{i=1}^{N} log p(y_i | \\mathbf{x}_i, \\mathbf{w})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to proceed further, we need a model about $p(y_i | \\mathbf{x}_i, \\mathbf{w})$. A conventient assumption is the Gaussina distribution. This assumption ensues the following [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$l(\\mathbf{w}) = \\frac{-1}{2\\sigma^2}RSS(\\mathbf{w}) - \\frac{N}{2} log(2\\pi \\sigma^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $RSS$ stands for the residual sums of squares (also known as sum of squared errors (SSE):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$RSS(\\mathbf{w}) = \\sum_{i=1}^{N}(y_i - \\mathbf{w}^T\\mathbf{x}_i)^2$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the residual as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\epsilon_i = y_i - \\mathbf{w}^T\\mathbf{x}_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can write the $RSS$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$RSS(\\mathbf{w}) = ||\\boldsymbol{\\epsilon}||_{2}^{2} = \\sum_{i=1}^{N}\\epsilon_{i}^2$$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the MLE estimator for $\\mathbf{w}$ minimizes the RSS (the last expression for  $l(\\mathbf{w})$ only depends on $RSS$), so this method is known as <a href=\"https://en.wikipedia.org/wiki/Least_squares\">least squares</a> [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"normal_equations\"></a> Normal equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simple problems, the solution to the minimization problem can be obtained using the normal equations [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathbf{X}^T\\mathbf{X}\\mathbf{w} = \\mathbf{X}^T\\mathbf{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which results into the following estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathbf{\\hat{w}}_{OLS} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"how_good_is_the_fit\"></a> How Good Is The Fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we established the linear regression  model but how can we measure how good it is?\n",
    "One metric to do so is the so-called ```R^2``` Coefficient also called the Coefficient of determination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"r2_coefficient\"></a> $R^2$ coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient is defined as\n",
    "\n",
    "![R2](r2.gif)\n",
    "\n",
    "where  SSR and SST are defined respectively as\n",
    "\n",
    "\n",
    "![SSR](ssr.gif)\n",
    "\n",
    "![SST](sst.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"include_files\"></a> Include files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#include \"cubic_engine/base/cubic_engine_types.h\"\n",
    "#include \"cubic_engine/ml/supervised_learning/regressor.h\"\n",
    "#include \"cubic_engine/optimization/serial_gradient_descent.h\"\n",
    "#include \"cubic_engine/optimization/utils/gd_control.h\"\n",
    "\n",
    "#include \"kernel/maths/functions/real_vector_polynomial.h\"\n",
    "#include \"kernel/maths/errorfunctions/mse_function.h\"\n",
    "#include \"kernel/utilities/data_set_loaders.h\"\n",
    "\n",
    "#include <iostream>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"m_func\"></a> The main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "int main(){\n",
    "\n",
    "    using cengine::uint_t;\n",
    "    using cengine::real_t;\n",
    "    using cengine::DynMat;\n",
    "    using cengine::DynVec;\n",
    "    using cengine::GDControl;\n",
    "    using cengine::Gd;\n",
    "    using cengine::LinearRegression;\n",
    "    using kernel::RealVectorPolynomialFunction;\n",
    "    using kernel::MSEFunction;\n",
    "\n",
    "    try{\n",
    "\n",
    "        auto dataset = kernel::load_car_plant_dataset();\n",
    "\n",
    "        // The regressor to use. use a hypothesis of the form\n",
    "        // f = w_0 + w_1*x_1\n",
    "        // set initial weights to 0\n",
    "        LinearRegression regressor({0.0, 0.0});\n",
    "\n",
    "        // the error function to to use for measuring the error\n",
    "        MSEFunction<RealVectorPolynomialFunction,\n",
    "                    DynMat<real_t>,\n",
    "                    DynVec<uint_t>> mse(regressor.get_model());\n",
    "\n",
    "        GDControl control(10000, kernel::KernelConsts::tolerance(), GDControl::DEFAULT_LEARNING_RATE);\n",
    "        control.show_iterations = false;\n",
    "        Gd gd(control);\n",
    "\n",
    "        auto result = regressor.train(dataset.first, dataset.second, gd, mse);\n",
    "        std::cout<<result<<std::endl;\n",
    "\n",
    "        std::cout<<\"Intercept: \"<<regressor.coeff(0)<<\" slope: \"<<regressor.coeff(1)<<std::endl;\n",
    "\n",
    "        DynVec<real_t> point{1.0, 5.7};\n",
    "        auto value = regressor.predict(point);\n",
    "\n",
    "        std::cout<<\"Value: \"<<value<<std::endl;\n",
    "    }\n",
    "    catch(std::exception& e){\n",
    "\n",
    "        std::cerr<<e.what()<<std::endl;\n",
    "    }\n",
    "    catch(...){\n",
    "\n",
    "        std::cerr<<\"Unknown exception occured\"<<std::endl;\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"results\"></a> Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# iterations:..7322\n",
    "# processors:..1\n",
    "# threads:.....1\n",
    "Residual:......9.99585e-09\n",
    "Tolerance:.....1e-08\n",
    "Convergence:...Yes\n",
    "Total time:....0.118251\n",
    "Learning rate:..0.01\n",
    "\n",
    "Intercept: 0.385994 slope: 0.415595\n",
    "Value: 2.75489\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"source_code\"></a> Source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"../exe.cpp\">exe.cpp</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"refs\"></a> References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Kevin P. Murphy, ```Machine Learning A Probabilistic Perspective```, The MIT Press\n",
    "2. <a href=\"https://en.wikipedia.org/wiki/Linear_regression\">Linear regression</a>\n",
    "3. <a href=\"https://en.wikipedia.org/wiki/Least_squares\">Least squares</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
